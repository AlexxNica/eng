---
title: Joyent Engineering Guide
markdown2extras: wiki-tables, code-friendly
---

# Joyent Engineering Guide

**Note: Despite the tone below, this guide is still a work in progress.
Everything here is subject to change as we discuss it with the team.**

This document describes standards and best practices for software development at
Joyent. These standards are intended to maintain product quality and to provide
consistency across codebases to make it easier for all engineers to learn new
parts of the system. This latter goal is important to encourage everyone to feel
comfortable diving into all parts of the system, as is often necessary when
debugging.

It's important to remember that all situations are unique, so rules should not
be followed blindly. However, these guidelines represent the best practices
agreed upon by the team. If you feel it necessary to diverge from them, that's
okay, but be prepared to explain why.

Note: In this document, services implementing an API are referred to as APIs.
For example, "MAPI" denotes the service implementing the MAPI API.


# Repository Guidelines

These guidelines cover naming, structure, and processes around repositories.
A template repository is included in this repo so you can quickly get something
working that follows these guidelines.


## Rule #1: FCS Quality All the Time

In general, use the "master" branch for development and releases. **"master"
should be FCS (First Customer Ship) quality at all times.** Although releases
are technically cut from release-specific branches, these branches are not
expected to diverge significantly from "master" at the time the branch was cut
except for fixes backported after the cut. That is, development should not be
ongoing in the release branches.

When working on large features, it's tempting to use development branches that
eventually get integrated into master. Indeed, this is sometimes necessary.
However, it should be avoided when possible, as it means people are running dev
branches rather than "master", which can lead to a [quality death spiral
(QDS)](http://hub.opensolaris.org/bin/view/Community+Group+on/qual_death_spiral)
as fewer people actually run the mainline tree. Where possible, consider
whether larger projects can be split into reasonably-sized chunks that can
individually be integrated into "master" without breaking existing
functionality. This allows you to continue developing on "master" while still
being able to commit frequently.


## Repository Naming

For repositories representing an API, the repo name that matches how the API is
discussed (spoken, chatted and emailed) means you'll get the repo name right on
first guess. If you can get away with it, a repo named after the abbreviate API
name is best. For example:
    
    Network API -> NAPI -> napi.git          # Good.
                        -> network-api.git   # Less good.
                        -> network_api.git   # Even less good.
                        -> NAPI.git          # Whoa! Capital letters are crazy here.


## Language

New server-side projects should almost certainly use Node.js with C/C++
components as needed. Consolidating onto one language makes it easier for
everyone to dig into other teams' projects as needed (for development as well as
debugging) and allows us to share code and tools.


## Directory Layout

Here is a suggested directory/file structure for your repository. All
repos must have a `README.md` and `Makefile`. The others are suggested
namings for particular usages, should your repo require them.

    build/          Built bits.
    deps/           Git submodules and/or commited 3rd-party deps should go
                    here. See "node_modules/" for node.js deps.
    docs/           Project docs. Uses <https://github.com/trentm/restdown>.
    lib/            JavaScript source files.
    node_modules/   Node.js deps, either populated at build time or commited.
                    See Managing Dependencies.
    pkg/            Package lifecycle scripts
    smf/manifests   SMF manifests
    smf/methods     SMF method scripts
    src/            C/C++ source files.
    test/           Test suite. node-tap prefered.
    tools/          Miscellaneous dev/upgrade/deployment tools and data.
    Makefile        See below.
    package.json    npm module info, if applicable (holds the project version)
    README.md       See below.


"docs" or "doc"? "test" or "tst"? We're not being religious about the
directory names, however the Makefile target names should use the names
specified below to allow automated build tools to rely on those names. The
reason to suggest "docs" and "test" as the directory names is to have the
same name as the Makefile targets.


### README.md

Every repository should have in its root a README.md (Markdown) file that
describes the repo and covers:

* the name of the API or other component(s) contained in the repo and a brief
  description of what they do
* the JIRA project for this repo (and any additional instructions, like how JIRA
  components are used for this project)
* owners of the project
* the style and lint configurations used, any additional pre-commit checks, and
  any non-standard useful Makefile targets
* some overview of the structure of the project, potentially including
  descriptions of the subcomponents, directory structure, and basic design
  principles
* basic development workflow: how to run the code and start playing with it

It's strongly recommended to start with the template in this repo.


### Makefile

All repos should have a Makefile that defines at least the following targets:

* `all`: builds all intermediate objects (e.g., binaries, executables, docs,
  etc.). This should be the default target.
* `check`: checks all files for adherence to lint, style, and other
  repo-specific rules not described here.
* `clean`: removes all built files
* `prepush`: runs all checks/tests required before pushing changes to the repo
* `docs`: builds documentation (restdown)
* `test`: runs the automated test suite
* `release`: build releasable artifacts, e.g. a tarball (for projects that
  generate release packages)

The `check` and `test` targets should fail if they find any 'check' violations
or failed tests. The `prepush` target is intended to cover all pre-commit
checks. It should run successfully before any push to the repo. It should also
be part of the automated build. Any commit which introduces a prepush failure
should be fixed immediately or backed out. A typical prepush target will
look like the following, but some non-code repositories might differ (e.g.
not have a test suite):

    prepush: check test
            @echo "Okay to push."


## Coding Style

Every repository must have a consistent coding style that is enforced by some
tool. Existing style-checking tools include:

* C: [cstyle](https://github.com/joyent/illumos-joyent/blob/master/usr/src/tools/scripts/cstyle.pl)
* JavaScript: [jsstyle](https://github.com/davepacheco/jsstyle)

Both of these tools (which are 90% the same anyway) support overriding style
checks on a per-line basis (e.g., for literal regular expressions).

It's not necessary that all projects use the same style, though it's strongly
suggested to keep differences to a minimum (e.g., only hard vs. soft tabs and
tabstops). Feel free add options to the above tools to allow for such
flexibility, or to write new tools. All styles should limit line length to 80
columns.

Make target: "check-style"

*Note: It is understood that `jsstyle` currently isn't configurable for all
the current common JavaScript styles in Joyent repositories. Adding support
for those styles to jsstyle (or a separate tool) should be done, but
prioritize accordingly with actual product work.*


## Lint

Every C repository must run "lint" and every JavaScript repository must run
[javascriptlint](http://github.com/davepacheco/javascriptlint) and both must be
lint-clean. Note that lint is not the same as style: lint covers objectively
dangerous patterns like undeclared variables, while style covers subjective
conventions like spacing.

Both lint and javascriptlint are very configurable. Projects may choose to
enable and disable particular sets of checks as they deem appropriate.  Most
checks can be disabled on a per-line basis. As with style, it's recommended
that we minimize divergence between repositories.

Make target: "check-lint" 


## Testing

All repos should include a comprehensive automated test suite, preferably using
node-tap. Bug fixes and new features should not be integrated without
considering adding new tests.

Make target: "test"


## Documentation

### API Documentation

You should use [restdown](https://github.com/trentm/restdown). Please discuss
with Trent if this isn't workable for your project.

Restdown is a tool for creating docs (and especially REST API docs) using a
single Markdown file with a few added conventions. You can set it up as
follows. Get the restdown tool:

    git submodule add git://github.com/trentm/restdown.git deps/restdown
    cd deps/restdown/
    git checkout 1.2.15    # let's use a restdown release tag

Get a starter restdown file:

    mkdir -p docs/media/img
    cp ../eng/docs/boilerplateapi.restdown docs/index.restdown
    cp ../eng/docs/media/img/favicon.ico docs/media/img/
    cp ../eng/docs/media/img/logo.png docs/media/img/

Tell the Makefile about it (`make docs`):

    DOC_FILES = docs/index.restdown

TODO: Finish off static serving of the docs in server.js.


### Code Documentation

Consider adding a block comment at the top of every file that describes at a
high level the component that's implemented in the file. For example:

    /*
     * ca-profile.js: profile support
     *
     * Profiles are sets of metrics.  They can be used to limit visibility of
     * metrics based on module, stat, or field names, or to suggest a group of
     * metrics to a user for a particular use case.
     */

For non-trivial subsystems, consider adding a Big Theory statement that
describes what the component does, the external interface, and internal details.
For a great example, check out
[panic.c](https://github.com/joyent/illumos-joyent/blob/master/usr/src/uts/common/os/panic.c#L29)
in the kernel.

Consider keeping design documents in restdown inside the repo. It's okay to have
one-off documents for specific projects, even if they become out of date as the
code evolves, but make clear in the document that the content may be out of
date. Keep such docs separate from general design documents that are kept up to
date.


### Man Pages

XXX use ronn. Is ronnjs acceptable now? If so, document then and add examples.
XXX use normal man page syntax for existing repos (illumos-joyent)


## Managing Node Dependencies

There are several ways of managing Node dependencies, each with notable pros
and cons. Choose whatever method works best for you, but try to be consistent
within a given repo. Either way, "make all" and other "make" targets should
automatically take care of setting up dependencies.

*Note: From the length of this section, it should be obvious that this
isn't full baked yet. We need some more experience.*


### Method 1: Commit node_modules to Git

In short: `npm install` to install all your deps, `git add node_modules`,
and commit. For binary modules: exclude binary bits and use `npm rebuild`
at build time.

This should be simple and easy to manage. However there are some remaining
questions on implementing this in general:

- Are there difficulties with the `git add node_modules` due to .gitignore
  files in the deps? "node_modules" is a common entry in many node modules'
  .gitignore files. Perhaps just deleting them all is sufficient
  (.npmignore vs. .gitignore).
- Do "devDependencies" get in the way here? Presumably we wouldn't commit
  dev dependencies. Perhaps specific "node_modules/my-dev-dep" entries
  in ".gitignore" would suffice.
- TODO: spec the .gitignore entries to facilitate excluding binary bits
  in the `git add node_modules`.

Lingering debate: This method is a unsavoury because it goes against a common
best practice to avoid commiting derived files (while not necessarily binary,
files in a published npm package are 'built' in a sense). The risk is that
these files could be changed by hand, intentionally or otherwise. This could
be good, if you decide that's the best way to float a patch on the package,
but it also means the source could become inconsistent with any published
version of the package without anyone realizing it. You can't easily tell
whether source files have been individually changed this way.

Counter argument: The alternative to commiting derived files is to build, or
otherwise get, them at build time. That needs to be reproducible.
Unfortunately without support for a type of npm "freeze" command to control
specific module versions `npm install` isn't reproducible (see method #3
below). As well, reliance on registry.npmjs.org is a build-time single
point of failure. On the plus side: all relevant sources are there in your
repo. Yes there is some noise from that, but having a history of those
code changes isn't to be sniffed at. A suggestion for the "floating patches"
is to create a fork of the module (e.g.
[trentm-datetime](http://search.npmjs.org/#/trentm-datetime)
for [datetime](http://search.npmjs.org/#/datetime)) until patches are
released upstream.


### Method 2: Git Submodules for Sources

Use git submodules to get the source for all dependent packages,
`git submodule add git://github.com/bob/my-dep.git deps/my-dep`, and use
`npm install deps/my-dep` at build time.
    
This avoids the inconsistency problem described above, but may make it harder
to float patches, and it may introduce a build-time dependency on another
source (like github). Also, git submodules are somewhat clumsy. As well,
some questions:

- Is there still a sub-dependency issue here? I.e. `npm install deps/my-dep`
  will still hit the npm registry for its deps (and so on). This makes
  this method suitable only for modules without their own deps.


### Method 3: List Specific Versions

List specific versions (e.g., "1.2.3" not "1.2") for all deps **and all deps
of deps** in your top-level "package.json". Then `npm install` to get
specific versions of everything. You can check this by making sure there are
no "node_modules/*/node_modules" directories. With this method, you must be
sure that "npm install" doesn't pull packages in from the public repository,
as builds should not depend on external resources.

The "./tools/npmfreeze.js" tool in this repo can help you put together that
list of versions.

Questions/Concerns:

- XXX Dap, I'm not sure exactly what you mean by the sentence about the
  "public repository". Are you saying that using registry.npmjs.org is
  unacceptable because "foo@1.2.3" tomorrow could differ from "foo@1.2.3"
  tomorrow? Or more because hitting the internet at build time for this
  sucks? --Trent
- If two parts of the node\_modules tree include differnt versions of the
  same node module, then the higher version wins. It is possible that is
  a problem.
- This method requires vigilance and futzing around when adding new
  dependencies.


## Commit Comments and JIRA Tickets

In collaborating on a body of software as large as SDC, it's critical that the
issues and thought processes behind non-trivial code changes be documented,
whether that's through code comments, git commit comments, or JIRA tickets.
There are many cases where people other than the original author need to
examine the git log:

* An engineer in another area tries to understand a bug they've run into (in your
  repo or not), possibly as a result of a recent change. The easier it is for
  people to move between repos and understand recent changes, the more quickly
  bugs in master can be root-caused. This is particularly important to avoid an
  issue bouncing around between teams where the problem is *not*.
* An engineer in another area tries to understand when a feature or bugfix
  was integrated into your repo so that they can pull it down to use it.
* An engineer working on the same code base, possibly years later, needs to
  modify (or even rewrite) the same code to fix another bug. They need to
  understand why a particular change was made the way it was to avoid
  reintroducing the original bug (or introducing a new bug).
* A release engineer tries to better understand the risk and test impact of a
  change to decide whether it's appropriate to backport.
* A support engineer tries to better understand the risk and test impact of a
  change to decide whether it's appropriate for binary relief or hot patching.
* Product management wants to determine when a feature or bugfix was integrated.
* Automated tools want to connect commits to JIRA tickets.

To this end, we require that with every commit there should be a comment that
includes the list of JIRA tickets addressed with this commit and a synopsis of
the changes (*either* for the whole commit *or* for each change, one by one).
**Between the JIRA ticket and the commit comment itself, there should be
sufficient information for an engineer that's moderately familiar with the
code base, possibly years later but with source in hand, to understand how and
why the change was made.**

The worst case is when the thought process and issue list are nowhere: not in
the comments and not in the JIRA tickets.

### Commit Comments

Across Joyent we require that **each commit be associated with one or more JIRA
tickets and that those tickets be listed in the commit comments**. This way,
given either the commit or the JIRA ticket, one can find the other.

Historically, some repos (notably illumos-joyent and cloud-analytics) have
additionally required that tickets should not be reused for multiple commits in
the same repo except for very minor changes like fixing lint or style
warnings. This makes it easier to correlate tickets and commits, since there's
usually exactly one commit for each resolved ticket. It also makes it easier to
back out the changes for a particular project. For these repos, the git
comments for the commit consist of a single line per JIRA ticket being resolved
in the commit. Each line consists of the ticket identifier and the synopsis
exactly as it appears in JIRA (optionally truncated to 80 characters with
"..."):

    OS-147 vfsstat command to show VFS activity by zone
    OS-148 Update ziostat to coexist peacefully with vfsstat
    OS-149 New kstats to support vfsstat

This approach encourages short, descriptive ticket synopses. For repos that keep
track of code reviews (e.g., illumos-joyent), that information is appended like
this:

    OS-850 Add support for Intel copper quad I350 to igb.
    Reviewed by: Jerry Jelinek <jerry.jelinek@joyent.com>

In the rare cases where the same ticket is used for multiple commits, a
parenthetical is used to explain why:

    INTRO-581 move mdb_v8 into illumos-joyent (missing file)

This structure works well for established repos like illumos, but it's not
always appropriate. For new work on greenfield projects, it may not even make
sense to use more than one ticket until the project reaches a first milestone.

### JIRA Tickets

For bugs, especially those that a customer could hit, consider including
additional information in the JIRA ticket:

* An explanation of what happened and the root cause, referencing the source
  where appropriate. This can be useful to engineers debugging similar issues
  or working on the same area of code who want to understand exactly why a
  change was made.
* An explanation of how to tell if you've hit this issue. This can be pretty
  technical (log entries, tools to run, etc.). This can be useful for engineers
  to tell if they've hit this bug in development as well as whether a customer
  has hit the bug.
* A workaround, if any.

Of course, much of this information won't make sense for many bugs, so use your
judgment, but don't assume that you're the only person who will ever look at the
ticket.


# REST API Guidelines

It's strongly recommended to use
[restify](https://github.com/mcavage/node-restify) for all web services. Not
only will you leverage common code and test coverage, but restify gives you
features like DTrace observability, debuggability, throttling, and versioning
out of the box. If it doesn't support something you need, consider adding it
rather than rolling your own.


## XXX Naming Endpoints

TODO: codify some of MarkC's and my (mostly mark) discussions on naming of
API endpoints.



# Best Practices

- Use JSON for config data. Not ini files: iniparser module has bugs, there
  are always questions about encoding non-string values.
- For services and distributed systems, consider building rich tools to
  understand the state of the service, like lists of the service's objects and
  information about each one. Think of the SmartOS proc(1) tools (see man pages
  for pgrep, pstack, pfiles, pargs).
- Consider doing development inside a SmartOS zone rather than on your Macbook
  or a COAL global zone. That forces us to use our product the way customers
  might, and it eliminates classes of problems where the dev environment doesn't
  match production.
- Whether you develop in COAL or on your Macbook, document what's necessary to
  get from scratch to a working development environment so that other people can
  try it out. Ideally, automate it. Having a script is especially useful if you
  do develop on COAL, which also forces you to keep it up to date.
- Similarly, build tools to automate deploying bits to a test system (usually a
  SmartOS headnode zone). The easier it is to test the actual deployment, the
  more likely people will actually test that, and you'll catch environment
  issues in development instead of after pushing.


# Examples

- The [boilerplate API](boilerplateapi.html) example in this repo gives you a
  starter file and some suggestions on how to document a web service.

